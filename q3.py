# -*- coding: utf-8 -*-
"""Q3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SVyn9gnvrg05WO-HLLjD9f95tlWTCCRp
"""

import logging
import os

import numpy as np
import torch
import yaml
from torchvision.utils import save_image

from dataset import SimpleDataset
from model import ModelConfig, ConvolutionGenerator, LinearGenerator
from trainer import TrainConfig
from utils import set_seed


def denormalize(images):
    out = (images + 1) / 2
    return out.clamp(0, 1)


"""# Make Dataset"""


def make_dataset(images, labels, conf, fake_images=None, fake_labels=None, fake_conf=None, real_ratio=1.0):
    # Images: (60000, 28, 28)
    # labels: (60000, 1)
    # conf:   (60000, 1)

    N = np.shape(labels)[0]

    """Combine the 2 Dataset"""
    idx = np.random.choice(N, real_ratio * N, replace=False)
    fake_idx = np.random.choice(N, (1 - real_ratio) * N, replace=False)
    image_data = images[idx, :, :]
    label_data = labels[idx, :]
    conf = conf[idx, :]
    fake_imageData = fake_images[fake_idx, :, :]
    fake_labelData = fake_labels[fake_idx, :]
    fake_conf = fake_conf[fake_idx, :]
    new_images = np.concatenate((image_data, fake_imageData), axis=0)
    new_labels = np.concatenate((label_data, fake_labelData), axis=0)
    new_confs = np.concatenate((conf, fake_conf), axis=0)

    """Sort by confidence"""
    n = np.argsort(-new_confs, axis=0)
    n = np.squeeze(n, axis=-1)
    new_images = new_images[n, :, :]
    new_labels = new_labels[n, :]

    dataset = SimpleDataset(new_images, new_labels)

    return dataset


"""# Generate Images """


def generate_images(generator, config, N=60000):
    device = torch.device('cpu')
    if torch.cuda.is_available():
        device = torch.cuda.current_device()
        generator = torch.nn.DataParallel(generator.to(device))

    ones = torch.ones(N // 10)

    z = torch.randn(N, config.latent_size).to(device)
    fake_y = torch.cat([ones * 0, ones * 1, ones * 2, ones * 3, ones * 4,
                        ones * 5, ones * 6, ones * 7, ones * 8, ones * 9], dim=0).long().to(device)
    # z = torch.randn(1, config.latent_size).to(device)
    # fake_y = torch.tensor(3 * torch.ones(1)).long().to(device)
    # print(fake_y)
    fake_images = generator(z, fake_y)
    fake_images = np.squeeze(fake_images, axis=1)
    # print(np.shape(fake_images))
    # (N, 28, 28)
    save_image(denormalize(fake_images[0, :, :]),
               os.path.join("figure", "fake_image_test_.png"))

    return fake_images


"""# Get Confidence"""


def classify(classifier, images):
    conf = np.array([])

    return conf, labels


"""# Main"""

logging.basicConfig(
    format="%(asctime)s - %(levelname)s - %(name)s - %(message)s",
    datefmt="%m/%d/%Y %H:%M:%S",
    level=logging.INFO,
)

if __name__ == '__main__':
    set_seed(42)

    tyaml = yaml.load(open(f'config/train.yaml', 'r'), Loader=yaml.FullLoader)
    tconf = TrainConfig(tyaml)

    images = np.load(f'data/{tyaml["dataset"]}_images.npy')
    labels = np.load(f'data/{tyaml["dataset"]}_labels.npy')

    """Generate images"""
    myaml = yaml.load(open('config/model.yaml', 'r'), Loader=yaml.FullLoader)
    mconf = ModelConfig(myaml)
    linear_generator = LinearGenerator(mconf)
    conv_generator = ConvolutionGenerator(mconf)

    generator = conv_generator.to()
    generator.load_state_dict(torch.load(
        'weights/200/G_200.ckpt'))

    fake_images = generate_images(generator, tconf)

    # classifier = Classifier()
    # classifier.load_stat_dict(torch.load(
    #     '.ckpt'))
    #
    # """Confidence value"""
    # conf, _ = classify(classifier, images)
    # fake_conf, fake_labels = classify(classifier, fake_images)
    #
    # """Mix the Dataset"""
    # real_ratio = 0.1  # [0.1, 0.2, 0.5, 1.0]
    # dataset = make_dataset(images, labels, conf, fake_images, fake_labels, fake_conf, real_ratio)

    """Training"""

    """Evaluation"""

"""# SandBox"""
#
# images = np.load(root + '/data/mnist_images.npy')
# labels = np.load(root + '/data/mnist_labels.npy')
# print(np.shape(images))
# print(np.shape(labels))
# # labels[:20]
# # images[1]
# # for i in range(np.shape(labels)[0]):
# # labels==i
# collections.Counter(labels[:30000])
#
# images = np.random.rand(3, 2, 2)
# conf = np.random.rand(3, 1)
# n = np.argsort(-conf, axis=0)
# print(np.shape(n))
# n = np.squeeze(n, axis=-1)
# # rearrange(n, 'A B C -> A B', A=2, B=2, C=1)
# # print(conf)
# # new_images = images[:,n,:,:]
# print(n)
# print("images", images)
# # for i in range(np.shape(images)[0]):
# # images[i] = images[i, n[i], :, :]
# images = images[n]
# print("images", images)
# # print("new_images",new_images)
# print(np.shape(images))
