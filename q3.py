# -*- coding: utf-8 -*-
"""Q3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SVyn9gnvrg05WO-HLLjD9f95tlWTCCRp
"""

import logging
import os

import numpy as np
import torch
import torch.nn as nn
import yaml
from torchvision.utils import save_image
import torchvision.datasets
from torchvision import transforms

from dataset import NewSimpleDataset
from model import ModelConfig, ConvolutionGenerator, LinearGenerator
from trainer import TrainConfig
from utils import set_seed
from classifier.model import CNNClassifier
from classifier.main import training
from small_classifier.TestCNN import ConvNet
from torch.utils.data import DataLoader

def denormalize(images):
    out = (images + 1) / 2
    return out.clamp(0, 1)


"""# Make Dataset"""


def make_dataset(images, labels, conf, fake_images=None, fake_labels=None, fake_conf=None, real_ratio=1.0):
    # Images: (60000, 28, 28)
    # labels: (60000, 1)
    # conf:   (60000, 1)
    device = torch.device('cpu')
    if torch.cuda.is_available():
        device = torch.cuda.current_device()

    N = labels.size(0)
    fake_N = fake_labels.size(0)

    # """Shuffle the fake dataset"""
    indices = torch.randperm(fake_N)
    fake_labels = fake_labels[indices]
    fake_conf = fake_conf[indices]
    fake_images = fake_images[indices]

    """Combine the 2 Dataset"""
    # idx = np.random.choice(N, real_ratio * N, replace=False)
    # fake_idx = np.random.choice(N, (1 - real_ratio) * N, replace=False)
    idx = int(real_ratio * N)
    fake_idx = int((1 - real_ratio) * idx)
    image_data = images[:idx, :, :].to(device)
    label_data = labels[:idx].to(device)
    conf = conf[:idx].to(device)
    fake_imageData = fake_images[:fake_idx, :, :].to(device)
    fake_labelData = fake_labels[:fake_idx].to(device)
    fake_conf = fake_conf[:fake_idx].to(device)
    new_images = torch.cat((image_data, fake_imageData), dim=0)
    new_labels = torch.cat((label_data, fake_labelData), dim=0)
    new_confs = torch.cat((conf, fake_conf), dim=0)

    """Sort by confidence"""
    n = torch.argsort(-new_confs).to(device)
    new_images = new_images[n, :, :]
    new_labels = new_labels[n]
    new_images = torch.unsqueeze(new_images, dim=1)
    dataset = NewSimpleDataset(new_images, new_labels)

    return dataset


"""# Generate Images """


def generate_images(generator, config, n=60000):
    device = torch.device('cpu')
    if torch.cuda.is_available():
        device = torch.cuda.current_device()
        # generator = torch.nn.DataParallel(generator.to(device))
    generator = generator.to(device)

    ones = torch.ones(n // 10)

    z = torch.randn(n, config.latent_size).to(device)
    fake_y = torch.cat([ones * 0, ones * 1, ones * 2, ones * 3, ones * 4,
                        ones * 5, ones * 6, ones * 7, ones * 8, ones * 9], dim=0).long().to(device)
    fake_images = generator(z, fake_y)
    fake_images = np.squeeze(fake_images, axis=1)
    save_image(denormalize(fake_images[0, :, :]),
               os.path.join("figure", "fake_image_test_.png"))

    return fake_images, fake_y


"""# Get Confidence"""


def classify(model, images, n=60000):
    device = torch.device('cpu')
    if torch.cuda.is_available():
        device = torch.cuda.current_device()

    model = model.to(device)
    images = images.type(torch.FloatTensor)
    images = images.to(device)
    images = images.unsqueeze(dim=1)
    batch_size = 512
    num_class = 10
    conf = torch.zeros(n, num_class)
    labels = torch.zeros(n)
    max = (n // batch_size) + 1
    soft_max = nn.Softmax(dim=1).to(device)

    model.eval()
    with torch.no_grad():
        for i in range(max):
            if i == max - 1:
                temp_conf = soft_max(model(images[batch_size * i:, :, :, :]))
                conf[batch_size * i:, :] = temp_conf
                labels[batch_size * i:] = torch.argmax(temp_conf, 1)
                break
            else:
                temp_conf = soft_max(model(images[batch_size * i:batch_size * (i + 1), :, :, :]))
                conf[batch_size * i:batch_size * (i + 1), :] = temp_conf
                labels[batch_size * i:batch_size * (i + 1)] = torch.argmax(temp_conf, 1)

    return conf.to(device), labels.to(device)


def classify_with_dataloader(model, data_loader, n=60000):
    device = torch.device('cpu')
    if torch.cuda.is_available():
        device = torch.cuda.current_device()

    model = model.to(device)

    init = True
    soft_max = nn.Softmax(dim=1).to(device)

    model.eval()
    for (x, y) in data_loader:
        x, y = x.cuda(0), y.cuda(0)

        with torch.no_grad():
            temp = soft_max(model(x))
            if init:
                conf = temp
                labels = torch.argmax(temp, 1)
                init = False
            else:
                conf = torch.cat((conf, temp), dim=0)
                labels = torch.cat((labels, torch.argmax(temp, 1)), dim=0)

    return conf.to(device), labels.to(device)


"""# Main"""

logging.basicConfig(
    format="%(asctime)s - %(levelname)s - %(name)s - %(message)s",
    datefmt="%m/%d/%Y %H:%M:%S",
    level=logging.INFO,
)

if __name__ == '__main__':
    set_seed(42)

    device = torch.device('cpu')
    if torch.cuda.is_available():
        device = torch.cuda.current_device()

    tyaml = yaml.load(open(f'config/train.yaml', 'r'), Loader=yaml.FullLoader)
    tconf = TrainConfig(tyaml)

    images = np.load(f'data/{tyaml["dataset"]}_images.npy')
    labels = np.load(f'data/{tyaml["dataset"]}_labels.npy')

    transf = transforms.Compose([
        transforms.Resize(32),
        transforms.ToTensor()
    ])
    mnist_train = torchvision.datasets.MNIST(root='data/',
                                             train=True,
                                             transform=transf,
                                             download=True)

    mnist_test = torchvision.datasets.MNIST(root='data/',
                                            train=False,
                                            transform=transf,
                                            download=True)

    train_loader = DataLoader(dataset=mnist_train,
                              batch_size=512,
                              shuffle=False,
                              num_workers=6,
                              drop_last=True)

    test_loader = DataLoader(dataset=mnist_test,
                             batch_size=2048,
                             shuffle=False,
                             num_workers=6,
                             drop_last=False)


    """Generate images"""
    myaml = yaml.load(open('config/model.yaml', 'r'), Loader=yaml.FullLoader)
    mconf = ModelConfig(myaml)
    linear_generator = LinearGenerator(mconf)
    conv_generator = ConvolutionGenerator(mconf)

    generator = conv_generator
    generator.load_state_dict(torch.load(
        'weights/200/G_200.ckpt'))
    # generator.load_state_dict(torch.load(
    #     'weights/200/G_200.ckpt', map_location=torch.device('cpu')))
    num_fake_images = 5000
    fake_images, fake_y = generate_images(generator, tconf, num_fake_images)
    # fake_images, fake_y = torch.zeros((2000, 32, 32)), torch.zeros((2000))

    classifier = CNNClassifier()
    classifier.load_state_dict(torch.load(
        'classifier/checkpoints/best.pt'))

    # classifier.load_state_dict(torch.load(
    #     'classifier/checkpoints/best.pt', map_location=torch.device('cpu')))

    # classifier = ConvNet()
    # classifier.load_state_dict(torch.load(
    #     'small_classifier/testModel.ckpt'))
    images_for_dataset = transforms.Resize(32)(mnist_train.data)

    """Get Confidence value"""
    fake_conf, fake_labels = classify(classifier, fake_images, num_fake_images)
    wrong_indices = (fake_labels != fake_y).nonzero()
    fake_conf[wrong_indices] = torch.zeros((1, 10), device=device)
    print("wrong labels: ", wrong_indices)
    conf, predicted_labels = classify(classifier, images_for_dataset, n=60000)

    """Mix the Dataset"""
    real_ratio = 0.98  # [0.1, 0.2, 0.5, 1.0]
    hello = torch.max(fake_conf, dim=1).values
    hello2 = torch.max(conf, dim=1).values
    wrong_indices = (torch.max(fake_conf, dim=1).values < 1.0).nonzero()
    print("wrong labels: ", wrong_indices)
    dataset = make_dataset(images_for_dataset, mnist_train.targets, torch.max(conf, dim=1).values, fake_images, fake_labels, torch.max(fake_conf, dim=1).values, real_ratio)

    """Training Classifier """
    training(dataset, test_loader)

    """Evaluation"""
