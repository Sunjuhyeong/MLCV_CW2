# -*- coding: utf-8 -*-
"""Q3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SVyn9gnvrg05WO-HLLjD9f95tlWTCCRp
"""

import logging
import os

import numpy as np
import torch
import yaml
from torchvision.utils import save_image
import torchvision.datasets
from torchvision import transforms

from dataset import SimpleDataset
from model import ModelConfig, ConvolutionGenerator, LinearGenerator
from trainer import TrainConfig
from utils import set_seed
from classifier.model import CNNClassifier
from small_classifier.TestCNN import ConvNet
from torch.utils.data import DataLoader


def denormalize(images):
    out = (images + 1) / 2
    return out.clamp(0, 1)


"""# Make Dataset"""


def make_dataset(images, labels, conf, fake_images=None, fake_labels=None, fake_conf=None, real_ratio=1.0):
    # Images: (60000, 28, 28)
    # labels: (60000, 1)
    # conf:   (60000, 1)

    N = np.shape(labels)[0]

    """Combine the 2 Dataset"""
    idx = np.random.choice(N, real_ratio * N, replace=False)
    fake_idx = np.random.choice(N, (1 - real_ratio) * N, replace=False)
    image_data = images[idx, :, :]
    label_data = labels[idx, :]
    conf = conf[idx, :]
    fake_imageData = fake_images[fake_idx, :, :]
    fake_labelData = fake_labels[fake_idx, :]
    fake_conf = fake_conf[fake_idx, :]
    new_images = np.concatenate((image_data, fake_imageData), axis=0)
    new_labels = np.concatenate((label_data, fake_labelData), axis=0)
    new_confs = np.concatenate((conf, fake_conf), axis=0)

    """Sort by confidence"""
    n = np.argsort(-new_confs, axis=0)
    n = np.squeeze(n, axis=-1)
    new_images = new_images[n, :, :]
    new_labels = new_labels[n, :]

    dataset = SimpleDataset(new_images, new_labels)

    return dataset


"""# Generate Images """


def generate_images(generator, config, n=60000):
    device = torch.device('cpu')
    if torch.cuda.is_available():
        device = torch.cuda.current_device()
        # generator = torch.nn.DataParallel(generator.to(device))
    generator = generator.to(device)

    ones = torch.ones(n // 10)

    z = torch.randn(n, config.latent_size).to(device)
    fake_y = torch.cat([ones * 0, ones * 1, ones * 2, ones * 3, ones * 4,
                        ones * 5, ones * 6, ones * 7, ones * 8, ones * 9], dim=0).long().to(device)
    fake_images = generator(z, fake_y)
    fake_images = np.squeeze(fake_images, axis=1)
    save_image(denormalize(fake_images[0, :, :]),
               os.path.join("figure", "fake_image_test_.png"))

    return fake_images, fake_y


"""# Get Confidence"""


def classify(model, images, n=60000):
    # device = torch.device('cpu')
    # if torch.cuda.is_available():
    #     device = torch.cuda.current_device()

    # model = model.to(device)
    # images = images.to(device)

    model.eval()
    with torch.no_grad():
        conf = model(images)
    labels = torch.argmax(conf, 1)

    return conf, labels


"""# Main"""

logging.basicConfig(
    format="%(asctime)s - %(levelname)s - %(name)s - %(message)s",
    datefmt="%m/%d/%Y %H:%M:%S",
    level=logging.INFO,
)

if __name__ == '__main__':
    set_seed(42)

    tyaml = yaml.load(open(f'config/train.yaml', 'r'), Loader=yaml.FullLoader)
    tconf = TrainConfig(tyaml)

    images = np.load(f'data/{tyaml["dataset"]}_images.npy')
    labels = np.load(f'data/{tyaml["dataset"]}_labels.npy')

    transforms = transforms.Compose([
        transforms.Resize(32),
        transforms.ToTensor()
    ])
    mnist_train = torchvision.datasets.MNIST(root='data/',
                                             train=True,
                                             transform=transforms,
                                             download=True)

    mnist_test = torchvision.datasets.MNIST(root='data/',
                                            train=False,
                                            transform=transforms,
                                            download=True)

    train_loader = DataLoader(dataset=mnist_train,
                              batch_size=512,
                              shuffle=True,
                              num_workers=6,
                              drop_last=True)

    test_loader = DataLoader(dataset=mnist_test,
                             batch_size=2048,
                             shuffle=False,
                             num_workers=6,
                             drop_last=False)

    # for (x, y) in train_loader:
    #     x, y = x.cuda(0), y.cuda(0)

    """Generate images"""
    myaml = yaml.load(open('config/model.yaml', 'r'), Loader=yaml.FullLoader)
    mconf = ModelConfig(myaml)
    linear_generator = LinearGenerator(mconf)
    conv_generator = ConvolutionGenerator(mconf)

    generator = conv_generator
    generator.load_state_dict(torch.load(
        'weights/200/G_200.ckpt'))

    fake_images, fake_y = generate_images(generator, tconf, 10000)

    classifier = CNNClassifier()
    classifier.load_state_dict(torch.load(
        'classifier/checkpoints/best.pt'))

    # classifier = ConvNet()
    # classifier.load_state_dict(torch.load(
    #     'small_classifier/testModel.ckpt'))

    """Confidence value"""
    fake_conf, fake_labels = classify(classifier, fake_images, 10000)
    conf, predicted_labels = classify(classifier, images)

    """Mix the Dataset"""
    real_ratio = 0.1  # [0.1, 0.2, 0.5, 1.0]
    dataset = make_dataset(images, labels, conf, fake_images, fake_labels, fake_conf, real_ratio)

    """Training"""

    """Evaluation"""

"""# SandBox"""
#
# images = np.load(root + '/data/mnist_images.npy')
# labels = np.load(root + '/data/mnist_labels.npy')
# print(np.shape(images))
# print(np.shape(labels))
# # labels[:20]
# # images[1]
# # for i in range(np.shape(labels)[0]):
# # labels==i
# collections.Counter(labels[:30000])
#
# images = np.random.rand(3, 2, 2)
# conf = np.random.rand(3, 1)
# n = np.argsort(-conf, axis=0)
# print(np.shape(n))
# n = np.squeeze(n, axis=-1)
# # rearrange(n, 'A B C -> A B', A=2, B=2, C=1)
# # print(conf)
# # new_images = images[:,n,:,:]
# print(n)
# print("images", images)
# # for i in range(np.shape(images)[0]):
# # images[i] = images[i, n[i], :, :]
# images = images[n]
# print("images", images)
# # print("new_images",new_images)
# print(np.shape(images))
